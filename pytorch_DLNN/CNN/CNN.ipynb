{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f21d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e809626",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "  def __init__(self, hidden1_size: int, hidden_size2: int, output_size: int):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    self.flatten = torch.nn.Flatten()\n",
    "\n",
    "    self.fc1 = torch.nn.Linear(in_features=32*7*7, out_features=hidden1_size)\n",
    "    self.fc2 = torch.nn.Linear(in_features=hidden1_size, out_features=hidden_size2)\n",
    "    \n",
    "    self.ol = torch.nn.Linear(in_features=hidden_size2, out_features=output_size)\n",
    "  \n",
    "  def forward(self, input_data):\n",
    "    max_pooled_conv1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)(torch.nn.functional.relu(self.conv1(input_data)))\n",
    "    max_pooled_conv2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)(torch.nn.functional.relu(self.conv2(max_pooled_conv1)))\n",
    "\n",
    "    flattened = self.flatten(max_pooled_conv2)\n",
    "\n",
    "    fc1_out = torch.nn.functional.relu(self.fc1(flattened))\n",
    "    fc2_out = torch.nn.functional.relu(self.fc2(fc1_out))\n",
    "\n",
    "    # outputs = torch.nn.functional.softmax(self.ol(fc2_out))\n",
    "\n",
    "    return fc2_out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d89266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.randint(0, 255, (10000, 28, 28), dtype=torch.uint8)\n",
    "labels = torch.randint(0, 9, (10000,), dtype=torch.long)\n",
    "\n",
    "transormer = torchvision.transforms.Compose([torchvision.transforms.ConvertImageDtype(torch.float32),\n",
    "                                             torchvision.transforms.Normalize((0.5,), (0.5,))])\n",
    "transformed_data = transormer(images)\n",
    "\n",
    "# wraping images and labels\n",
    "input_data = torch.utils.data.TensorDataset(transformed_data, labels)\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(input_data, [8000, 2000])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, num_workers=1)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=64, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd9934b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c706920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=3.0185, Val Loss=2.9978, Val Acc=0.1025\n",
      "Epoch 2: Train Loss=2.9483, Val Loss=2.9975, Val Acc=0.1150\n",
      "Epoch 3: Train Loss=2.9437, Val Loss=2.9982, Val Acc=0.1130\n",
      "Epoch 4: Train Loss=2.9378, Val Loss=2.9990, Val Acc=0.1150\n",
      "Epoch 5: Train Loss=2.9296, Val Loss=3.0013, Val Acc=0.1110\n",
      "Epoch 6: Train Loss=2.9175, Val Loss=3.0055, Val Acc=0.1125\n",
      "Epoch 7: Train Loss=2.8998, Val Loss=3.0146, Val Acc=0.1135\n",
      "Epoch 8: Train Loss=2.8760, Val Loss=3.0276, Val Acc=0.1080\n",
      "Epoch 9: Train Loss=2.8443, Val Loss=3.0445, Val Acc=0.1175\n",
      "Epoch 10: Train Loss=2.8068, Val Loss=3.0628, Val Acc=0.1180\n",
      "Epoch 11: Train Loss=2.7613, Val Loss=3.0920, Val Acc=0.1175\n",
      "Epoch 12: Train Loss=2.7134, Val Loss=3.1256, Val Acc=0.1115\n",
      "Epoch 13: Train Loss=2.6608, Val Loss=3.1646, Val Acc=0.1145\n",
      "Epoch 14: Train Loss=2.6057, Val Loss=3.2192, Val Acc=0.1125\n",
      "Epoch 15: Train Loss=2.5486, Val Loss=3.2723, Val Acc=0.1125\n",
      "Epoch 16: Train Loss=2.4899, Val Loss=3.3278, Val Acc=0.1095\n",
      "Epoch 17: Train Loss=2.4392, Val Loss=3.3853, Val Acc=0.1125\n",
      "Epoch 18: Train Loss=2.3879, Val Loss=3.4452, Val Acc=0.1130\n",
      "Epoch 19: Train Loss=2.3400, Val Loss=3.5155, Val Acc=0.1095\n",
      "Epoch 20: Train Loss=2.2944, Val Loss=3.5900, Val Acc=0.1125\n",
      "Epoch 21: Train Loss=2.2539, Val Loss=3.6405, Val Acc=0.1110\n",
      "Epoch 22: Train Loss=2.0510, Val Loss=3.3913, Val Acc=0.1155\n",
      "Epoch 23: Train Loss=1.8989, Val Loss=3.4718, Val Acc=0.1125\n",
      "Epoch 24: Train Loss=1.8604, Val Loss=3.5478, Val Acc=0.1140\n",
      "Epoch 25: Train Loss=1.8417, Val Loss=3.6247, Val Acc=0.1075\n",
      "Epoch 26: Train Loss=1.8138, Val Loss=3.6587, Val Acc=0.1120\n",
      "Epoch 27: Train Loss=1.7772, Val Loss=3.7218, Val Acc=0.1120\n",
      "Epoch 28: Train Loss=1.7367, Val Loss=3.8199, Val Acc=0.1150\n",
      "Epoch 29: Train Loss=1.6935, Val Loss=3.9105, Val Acc=0.1155\n",
      "Epoch 30: Train Loss=1.6587, Val Loss=4.0056, Val Acc=0.1140\n",
      "Epoch 31: Train Loss=1.6234, Val Loss=4.0747, Val Acc=0.1110\n",
      "Epoch 32: Train Loss=1.5882, Val Loss=4.0887, Val Acc=0.1145\n",
      "Epoch 33: Train Loss=1.5565, Val Loss=4.1178, Val Acc=0.1190\n",
      "Epoch 34: Train Loss=1.5252, Val Loss=4.1550, Val Acc=0.1170\n",
      "Epoch 35: Train Loss=1.5134, Val Loss=4.2268, Val Acc=0.1125\n",
      "Epoch 36: Train Loss=1.5265, Val Loss=4.2850, Val Acc=0.1070\n",
      "Epoch 37: Train Loss=1.5527, Val Loss=4.3672, Val Acc=0.1120\n",
      "Epoch 38: Train Loss=1.5496, Val Loss=4.3024, Val Acc=0.1045\n",
      "Epoch 39: Train Loss=1.5099, Val Loss=4.3801, Val Acc=0.1065\n",
      "Epoch 40: Train Loss=1.4657, Val Loss=4.4445, Val Acc=0.1035\n",
      "Epoch 41: Train Loss=1.4255, Val Loss=4.5578, Val Acc=0.1045\n",
      "Epoch 42: Train Loss=1.3861, Val Loss=4.5959, Val Acc=0.1060\n",
      "Epoch 43: Train Loss=1.3600, Val Loss=4.6841, Val Acc=0.1060\n",
      "Epoch 44: Train Loss=1.3297, Val Loss=4.7715, Val Acc=0.1050\n",
      "Epoch 45: Train Loss=1.2948, Val Loss=4.8153, Val Acc=0.1065\n",
      "Epoch 46: Train Loss=1.2821, Val Loss=4.9400, Val Acc=0.1035\n",
      "Epoch 47: Train Loss=1.2536, Val Loss=5.0797, Val Acc=0.1055\n",
      "Epoch 48: Train Loss=1.2529, Val Loss=5.3327, Val Acc=0.1020\n",
      "Epoch 49: Train Loss=1.2372, Val Loss=5.7291, Val Acc=0.0975\n",
      "Epoch 50: Train Loss=1.2045, Val Loss=5.7083, Val Acc=0.1015\n",
      "Epoch 51: Train Loss=1.1874, Val Loss=5.7498, Val Acc=0.1005\n",
      "Epoch 52: Train Loss=1.1641, Val Loss=5.8223, Val Acc=0.1050\n",
      "Epoch 53: Train Loss=1.1416, Val Loss=5.8173, Val Acc=0.1000\n",
      "Epoch 54: Train Loss=0.9256, Val Loss=5.9908, Val Acc=0.1015\n",
      "Epoch 55: Train Loss=0.7440, Val Loss=6.3557, Val Acc=0.1055\n",
      "Epoch 56: Train Loss=0.7363, Val Loss=6.6663, Val Acc=0.1040\n",
      "Epoch 57: Train Loss=0.6779, Val Loss=6.8823, Val Acc=0.1015\n",
      "Epoch 58: Train Loss=0.6280, Val Loss=6.7727, Val Acc=0.1025\n",
      "Epoch 59: Train Loss=0.6294, Val Loss=6.4175, Val Acc=0.1010\n",
      "Epoch 60: Train Loss=0.6382, Val Loss=6.3047, Val Acc=0.1035\n",
      "Epoch 61: Train Loss=0.6143, Val Loss=6.5878, Val Acc=0.1045\n",
      "Epoch 62: Train Loss=0.5807, Val Loss=6.7181, Val Acc=0.1040\n",
      "Epoch 63: Train Loss=0.5430, Val Loss=6.6147, Val Acc=0.1045\n",
      "Epoch 64: Train Loss=0.5075, Val Loss=6.5257, Val Acc=0.1045\n",
      "Epoch 65: Train Loss=0.4865, Val Loss=6.5676, Val Acc=0.1040\n",
      "Epoch 66: Train Loss=0.4664, Val Loss=7.0819, Val Acc=0.1080\n",
      "Epoch 67: Train Loss=0.4442, Val Loss=7.5172, Val Acc=0.1070\n",
      "Epoch 68: Train Loss=0.4175, Val Loss=7.8399, Val Acc=0.1085\n",
      "Epoch 69: Train Loss=0.4126, Val Loss=7.9960, Val Acc=0.0990\n",
      "Epoch 70: Train Loss=0.4187, Val Loss=8.0706, Val Acc=0.1005\n",
      "Epoch 71: Train Loss=0.4066, Val Loss=8.1614, Val Acc=0.1025\n",
      "Epoch 72: Train Loss=0.3727, Val Loss=8.3861, Val Acc=0.1070\n",
      "Epoch 73: Train Loss=0.3674, Val Loss=8.2847, Val Acc=0.1045\n",
      "Epoch 74: Train Loss=0.3462, Val Loss=7.8897, Val Acc=0.1005\n",
      "Epoch 75: Train Loss=0.3669, Val Loss=7.9116, Val Acc=0.0985\n",
      "Epoch 76: Train Loss=0.3591, Val Loss=8.4600, Val Acc=0.1045\n",
      "Epoch 77: Train Loss=0.3281, Val Loss=8.9619, Val Acc=0.1040\n",
      "Epoch 78: Train Loss=0.3082, Val Loss=9.0063, Val Acc=0.0990\n",
      "Epoch 79: Train Loss=0.3122, Val Loss=9.1510, Val Acc=0.0965\n",
      "Epoch 80: Train Loss=0.3229, Val Loss=9.2658, Val Acc=0.0985\n",
      "Epoch 81: Train Loss=0.3475, Val Loss=8.6448, Val Acc=0.0970\n",
      "Epoch 82: Train Loss=0.3244, Val Loss=8.2801, Val Acc=0.1015\n",
      "Epoch 83: Train Loss=0.2785, Val Loss=8.4165, Val Acc=0.1020\n",
      "Epoch 84: Train Loss=0.2600, Val Loss=8.8662, Val Acc=0.1080\n",
      "Epoch 85: Train Loss=0.2342, Val Loss=9.2544, Val Acc=0.1060\n",
      "Epoch 86: Train Loss=0.2305, Val Loss=9.2459, Val Acc=0.1045\n",
      "Epoch 87: Train Loss=0.2402, Val Loss=9.2043, Val Acc=0.1015\n",
      "Epoch 88: Train Loss=0.2338, Val Loss=9.0156, Val Acc=0.1030\n",
      "Epoch 89: Train Loss=0.2547, Val Loss=9.0227, Val Acc=0.1025\n",
      "Epoch 90: Train Loss=0.2529, Val Loss=8.9374, Val Acc=0.0980\n",
      "Epoch 91: Train Loss=0.2560, Val Loss=9.2041, Val Acc=0.0975\n",
      "Epoch 92: Train Loss=0.2173, Val Loss=9.7939, Val Acc=0.1045\n",
      "Epoch 93: Train Loss=0.1825, Val Loss=10.1666, Val Acc=0.1065\n",
      "Epoch 94: Train Loss=0.1673, Val Loss=10.3614, Val Acc=0.1045\n",
      "Epoch 95: Train Loss=0.1716, Val Loss=10.1305, Val Acc=0.1050\n",
      "Epoch 96: Train Loss=0.1683, Val Loss=10.0181, Val Acc=0.1060\n",
      "Epoch 97: Train Loss=0.1552, Val Loss=10.2169, Val Acc=0.1100\n",
      "Epoch 98: Train Loss=0.1470, Val Loss=10.3749, Val Acc=0.1050\n",
      "Epoch 99: Train Loss=0.1366, Val Loss=10.1630, Val Acc=0.1070\n",
      "Epoch 100: Train Loss=0.1261, Val Loss=10.7909, Val Acc=0.1050\n"
     ]
    }
   ],
   "source": [
    "model = CNN(hidden1_size=64, hidden_size2=64, output_size=10).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  train_loss = 0\n",
    "  model.train()\n",
    "  for i, (images, labels) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images.unsqueeze(1))\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss += loss.item()\n",
    "  \n",
    "  model.eval()\n",
    "  val_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "      outputs = model(images.unsqueeze(1))\n",
    "      loss = criterion(outputs, labels)\n",
    "      val_loss += loss.item()\n",
    "      preds = outputs.argmax(dim=1)\n",
    "      correct += (preds == labels).sum().item()\n",
    "\n",
    "  val_acc = correct / len(val_data)\n",
    "  print(f\"Epoch {epoch+1}: Train Loss={train_loss/len(train_loader):.4f}, \"\n",
    "\t\t\t\tf\"Val Loss={val_loss/len(val_loader):.4f}, Val Acc={val_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
